openapi: 3.0.0

info:
  title: REST Admin API
  version: 3.0.0
  contact:
    name: Kafka REST Team
    url: https://confluent.slack.com/app_redirect?channel=kafka-rest-eng
    email: kafka-clients-proxy-team@confluent.io
  x-api-id: 499e3476-71e0-4d6f-b4f9-6776cec6df27
  x-api-group: v3
  x-audience: external-public
  x-tag-group: Kafka API (%s)

servers:
  - url: "{protocol}://{address}:{port}/v3"
    x-audience: component-internal
    description: Kafka REST Proxy. See https://docs.confluent.io/current/kafka-rest/index.html.
    variables:
      address:
        default: localhost
        description: Address of the server
      port:
        default: "8082"
        description: Port of the server
      protocol:
        default: http
        description: Protocol for interacting with server
        enum:
          - http
          - https

  - url: "{protocol}://{address}:{port}/kafka/v3"
    x-audience: component-internal
    description: Kafka REST Proxy as part of Confluent Server.
    variables:
      protocol:
        default: http
        enum:
          - http
          - https
        description: Protocol to communicate with the server
      address:
        default: localhost
        description: Address of the server
      port:
        default: "8090"
        description: Port of the server

  - url: https://pkc-00000.region.provider.confluent.cloud/kafka/v3
    x-audience: business-unit-internal
    description: Confluent Cloud REST Endpoint. For example https://pkc-00000.region.provider.confluent.cloud

paths:
  /clusters/{cluster_id}/topics/{topic_name}/records:
    parameters:
      - $ref: '#/components/parameters/ClusterId'
      - $ref: '#/components/parameters/TopicName'

    post:
      summary: 'Produce Records'
      operationId: produceRecord
      description: |-
        [![Generally Available](https://img.shields.io/badge/Lifecycle%20Stage-Generally%20Available-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

        Produce records to the given topic, returning delivery reports for each
                    record produced. This API can be used in streaming mode by setting "Transfer-Encoding:
                    chunked" header. For as long as the connection is kept open, the server will
                    keep accepting records. Records are streamed to and from the server as Concatenated 
                    JSON. For each record sent to the server, the server will
                    asynchronously send back a delivery report, in the same order, each with its own
                    error_code. An error_code of 200 indicates success. The HTTP status code will be HTTP 
                    200 OK as long as the connection is successfully established. To identify records
                    that have encountered an error, check the error_code of each delivery report.
      tags:
        - Records (v3)
      requestBody:
        $ref: '#/components/requestBodies/ProduceRequest'
      responses:
        '200':
          $ref: '#/components/responses/ProduceResponse'
        '400':
          $ref: '#/components/responses/BadRequestErrorResponse_ProduceRecords'
        '401':
          $ref: '#/components/responses/UnauthorizedErrorResponse'
        '403':
          $ref: '#/components/responses/ForbiddenErrorResponse'
        '404':
          $ref: '#/components/responses/NotFoundErrorResponse'
        '413':
          $ref: '#/components/responses/RequestEntityTooLargeErrorResponse'
        '415':
          $ref: '#/components/responses/UnsupportedMediaTypeErrorResponse'
        '422':
          $ref: '#/components/responses/UnprocessableEntity_ProduceRecord'
        '429':
          $ref: '#/components/responses/TooManyRequestsErrorResponse'
        '5XX':
          $ref: '#/components/responses/ServerErrorResponse'

  /clusters/{cluster_id}/topics/{topic_name}/records:batch:
    parameters:
      - $ref: '#/components/parameters/ClusterId'
      - $ref: '#/components/parameters/TopicName'

    post:
      summary: 'Produce Records Batch'
      operationId: produceRecordsBatch
      description: |-
        [![Generally Available](https://img.shields.io/badge/Lifecycle%20Stage-Generally%20Available-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

        Produce a batch of records to the given topic, returning delivery reports for each record produced.
        To identify records that have encountered an error, check the error_code of each delivery report.
      tags:
        - Records (v3)
      requestBody:
        $ref: '#/components/requestBodies/ProduceBatchRequest'
      responses:
        '207':
          $ref: '#/components/responses/ProduceBatchResponse'
        '400':
          $ref: '#/components/responses/BadRequestErrorResponse_ProduceRecords'
        '401':
          $ref: '#/components/responses/UnauthorizedErrorResponse'
        '403':
          $ref: '#/components/responses/ForbiddenErrorResponse'
        '404':
          $ref: '#/components/responses/NotFoundErrorResponse'
        '415':
          $ref: '#/components/responses/UnsupportedMediaTypeErrorResponse'
        '429':
          $ref: '#/components/responses/TooManyRequestsErrorResponse'
        '5XX':
          $ref: '#/components/responses/ServerErrorResponse'

components:
  parameters:
  
    ClusterId:
      name: 'cluster_id'
      description: 'The Kafka cluster ID.'
      in: path
      required: true
      schema:
        type: string
      example: 'cluster-1'

    TopicName:
      name: 'topic_name'
      description: 'The topic name.'
      in: path
      required: true
      schema:
        type: string
      example: topic-1

  schemas:
  
    AnyValue:
      nullable: true
  
    Error:
      type: object
      required:
        - error_code
        - message
      properties:
        error_code:
          type: integer
          format: int32
        message:
          type: string
          nullable: true

    ProduceBatchResponse:
      description: Response for producing a batch of records.
      type: object
      properties:
        successes:
          description: Successful batch results.
          type: array
          items:
            $ref: '#/components/schemas/ProduceBatchResponseSuccessEntry'
        failures:
          description: Failed batch results.
          type: array
          items:
            $ref: '#/components/schemas/ProduceBatchResponseFailureEntry'

    ProduceBatchResponseFailureEntry:
      type: object
      required:
        - id
        - error_code
      properties:
        id:
          description: Batch entry ID.
          type: string
          minLength: 1
          maxLength: 80
        error_code:
          description: Error code.
          type: integer
          format: int32
        message:
          description: Error message.
          type: string

    ProduceBatchResponseSuccessEntry:
      type: object
      required:
        - id
      properties:
        id:
          description: Batch entry ID.
          type: string
          minLength: 1
          maxLength: 80
        cluster_id:
          type: string
        topic_name:
          type: string
        partition_id:
          type: integer
          format: int32
        offset:
          type: integer
          format: int64
        timestamp:
          type: string
          format: date-time
          nullable: true
        key:
          $ref: '#/components/schemas/ProduceResponseData'
        value:
          $ref: '#/components/schemas/ProduceResponseData'

    ProduceResponse:
      type: object
      required:
        - error_code
      properties:
        error_code:
          type: integer
          format: int32
        message:
          type: string
        cluster_id:
          type: string
        topic_name:
          type: string
        partition_id:
          type: integer
          format: int32
        offset:
          type: integer
          format: int64
        timestamp:
          type: string
          format: date-time
          nullable: true
        key:
          $ref: '#/components/schemas/ProduceResponseData'
        value:
          $ref: '#/components/schemas/ProduceResponseData'

    ProduceResponseData:
      type: object
      required:
        - size
        - type
      properties:
        size:
          type: integer
          format: int64
        type:
          type: string
          x-extensible-enum:
            - BINARY
            - JSON
            - STRING
            - AVRO
            - JSONSCHEMA
            - PROTOBUF
          nullable: true
        subject:
          type: string
          nullable: true
        schema_id:
          type: integer
          nullable: true
        schema_version:
          type: integer
          nullable: true
      nullable: true

    ProduceBatchRequest:
      description: Request for producing a batch of records.
      type: object
      required:
        - entries
      properties:
        entries:
          type: array
          items:
            $ref: '#/components/schemas/ProduceBatchRequestEntry'

    ProduceBatchRequestEntry:
      type: object
      required:
        - id
      properties:
        id:
          description: Batch entry ID.
          type: string
          minLength: 1
          maxLength: 80
        partition_id:
          type: integer
          nullable: true
          format: int32
        headers:
          type: array
          items:
            $ref: '#/components/schemas/ProduceRequestHeader'
        key:
          $ref: '#/components/schemas/ProduceRequestData'
        value:
          $ref: '#/components/schemas/ProduceRequestData'
        timestamp:
          type: string
          format: date-time
          nullable: true

    ProduceRequest:
      type: object
      properties:
        partition_id:
          type: integer
          nullable: true
          format: int32
        headers:
          type: array
          items:
            $ref: '#/components/schemas/ProduceRequestHeader'
        key:
          $ref: '#/components/schemas/ProduceRequestData'
        value:
          $ref: '#/components/schemas/ProduceRequestData'
        timestamp:
          type: string
          format: date-time
          nullable: true

    ProduceRequestData:
      type: object
      properties:
        type:
          type: string
          x-extensible-enum:
            - BINARY
            - JSON
            - STRING
            - AVRO
            - JSONSCHEMA
            - PROTOBUF
        subject:
          type: string
          nullable: true
        subject_name_strategy:
          type: string
          x-extensible-enum:
            - TOPIC_NAME
            - RECORD_NAME
            - TOPIC_RECORD_NAME
          nullable: true
        schema_id:
          type: integer
          nullable: true
        schema_version:
          type: integer
          nullable: true
        schema:
          type: string
          nullable: true
        data:
          $ref: '#/components/schemas/AnyValue'
      nullable: true

    ProduceRequestHeader:
      type: object
      required:
        - name
      properties:
        name:
          type: string
        value:
          type: string
          format: byte
          nullable: true


  requestBodies:
    
    ProduceBatchRequest:
      description: 'A batch of records to be produced to Kafka. The delivery reports are sent in the response
                    in the same order as the records in the request.'
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/ProduceBatchRequest'
          examples:
            string_batch:
              description: 'If using type, one of "BINARY", "JSON" or "STRING" is required.'
              value:
                entries:
                  - id: "1"
                    value:
                      type: 'STRING'
                      data: 'My first message'
                  - id: "2"
                    value:
                      type: 'STRING'
                      data: 'My second message'

    ProduceRequest:
      description: 'A single record to be produced to Kafka. To produce multiple records in the same
                    request, simply concatenate the records. The delivery reports are concatenated
                    in the same order as the records are sent.'
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/ProduceRequest'
          examples:
            binary_and_json:
              description: 'If using type, one of "BINARY", "JSON" or "STRING" is required.'
              value:
                partition_id: 1
                headers:
                  - name: 'Header-1'
                    value: 'SGVhZGVyLTE='
                  - name: 'Header-2'
                    value: 'SGVhZGVyLTI='
                key:
                  type: 'BINARY'
                  data: 'Zm9vYmFy'
                value:
                  type: 'JSON'
                  data: {"foo":"bar"}
                timestamp: '2021-02-05T19:14:42Z'
            binary_and_avro_with_subject_and_raw_schema:
              description: 'If using type, one of "BINARY", "JSON", "STRING", or using the schema field is required.'
              value:
                partition_id: 1
                headers:
                  - name: 'Header-1'
                    value: 'SGVhZGVyLTE='
                  - name: 'Header-2'
                    value: 'SGVhZGVyLTI='
                key:
                  type: 'BINARY'
                  data: 'Zm9vYmFy'
                value:
                  type: 'AVRO'
                  subject: 'topic-1-key'
                  schema: '{\"type\":\"string\"}'
                  data: 'foobar'
                timestamp: '2021-02-05T19:14:42Z'
            string:
              description: 'If using type, one of "BINARY", "JSON" or "STRING" is required.'
              value:
                value:
                  type: 'STRING'
                  data: 'My message'
            schema_id_and_schema_version:
              description: 'If not setting type, the record is assumed to use a schema. The actual
                            schema is queried from Schema Registry based on the subject, schema_id
                            and schema_version. You can specify the subject directly or you can use
                            subject_name_strategy. If neither is specified, subject_name_strategy is
                            assumed to be TOPIC_NAME. You can use either schema_id or schema_version
                            to identify the actual schema in the subject.'
              value:
                key:
                  subject_name_strategy: 'TOPIC_NAME'
                  schema_id: 1
                  data: 1000
                value:
                  schema_version: 1
                  data:
                    foo: 'bar'
            latest_schema:
              description: 'If neither schema_id or schema_version are specified, the latest schema
                            for the subject is used. This should be the preferred way of using the
                            API. You should register the schema with Schema Registry directly, then
                            on Kafka REST you do not need to say anything about the schema and we
                            will fetch the latest one for you.'
              value:
                key:
                  data: 1000
                value:
                  data: 'foobar'
            null_and_empty_data:
              description: 'data can be omitted or can be null.'
              value:
                key:
                  schema_id: 1
                value:
                  schema_version: 1
                  data: null
            empty_value:
              description: 'key or value can be omitted entirely.'
              value:
                key:
                  data: 1000


  responses:

    ProduceBatchResponse:
      description: |-
        The response containing a delivery report for each record produced to a topic.
        A separate delivery report will be returned, in the same order, each with its own error_code.
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/ProduceBatchResponse'
          examples:
            produce_batch_record_success:
              description: The records were successfully produced to the topic.
              value:
                successes:
                  - id: "1"
                    cluster_id: 'cluster-1'
                    topic_name: 'topic-1'
                    partition_id: 1
                    offset: 0
                    timestamp: '2021-02-05T19:14:42Z'
                    key:
                      type: BINARY
                      size: 7
                    value:
                      type: JSON
                      size: 15
                  - id: "2"
                    cluster_id: 'cluster-1'
                    topic_name: 'topic-1'
                    partition_id: 1
                    offset: 1
                    timestamp: '2021-02-05T19:14:43Z'
                    key:
                      type: BINARY
                      size: 7
                    value:
                      type: JSON
                      size: 15
                failures: []
            produce_batch_record_success_and_failure:
              description: One record was produced to the topic successfully, and one failed.
              value:
                successes:
                  - id: "1"
                    cluster_id: 'cluster-1'
                    topic_name: 'topic-1'
                    partition_id: 1
                    offset: 0
                    timestamp: '2021-02-05T19:14:42Z'
                    key:
                      type: BINARY
                      size: 7
                    value:
                      type: JSON
                      size: 15
                failures:
                  - id: "2"
                    error_code: 400
                    message: "Bad Request: data=1 is not a base64 string."

    ProduceResponse:
      description: |-
        The response containing a delivery report for a record produced to a topic. In streaming mode,
        for each record sent, a separate delivery report will be returned, in the same order,
        each with its own error_code.
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/ProduceResponse'
          examples:
            produce_record_success:
              description: The record was successfully produced to the topic.
              value:
                error_code: 200
                cluster_id: 'cluster-1'
                topic_name: 'topic-1'
                partition_id: 1
                offset: 0
                timestamp: '2021-02-05T19:14:42Z'
                key:
                  type: BINARY
                  size: 7
                value:
                  type: JSON
                  size: 15
            produce_record_bad_binary_data:
              description: Thrown when sending a BINARY value which is not a base64-encoded string.
              value:
                error_code: 400
                message: "Bad Request: data=1 is not a base64 string."


    # Error responses

    BadRequestErrorResponse_ProduceRecords:
      description: 'Indicates a bad request error. It could be caused by an unexpected request
        body format or other forms of request validation failure.'
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
          examples:
            header_not_base64_encoded:
              description: "Thrown when headers in the produce-record are not base64 encoded."
              value:
                error_code: 400
                message: "Cannot deserialize value of type `byte[]` from String \"\": Unexpected end of base64-encoded String: base64 variant 'MIME-NO-LINEFEEDS' expects padding (one or more '=' characters) at the end. This Base64Variant might have been incorrectly configured"

    UnprocessableEntity_ProduceRecord:
      description: 'Indicates a bad request error. It could be caused by an unexpected request
        body format or other forms of request validation failure.'
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
          examples:
            produce_record_empty_request_body:
              description: "Thrown when the request body is empty."
              value:
                error_code: 422
                message: "Payload error. Request body is empty. Data is required."

    UnauthorizedErrorResponse:
      description: 'Indicates a client authentication error. Kafka authentication failures will contain
        error code 40101 in the response body.'
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
          examples:
            kafka_authentication_failed:
              description: "Thrown when using Basic authentication with wrong Kafka credentials."
              value:
                error_code: 40101
                message: "Authentication failed"

    ForbiddenErrorResponse:
      description: 'Indicates a client authorization error. Kafka authorization failures will contain
            error code 40301 in the response body.'
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
          examples:
            kafka_authorization_failed:
              description: "Thrown when the caller is not authorized to perform the underlying operation."
              value:
                error_code: 40301
                message: "Request is not authorized"

    NotFoundErrorResponse:
      description: 'Indicates attempted access to an unreachable or non-existing resource like e.g. an unknown topic
        or partition. GET requests to endpoints not allowed in the accesslists will also result in this response.'
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
          examples:
            endpoint_not_found:
              description: "Thrown for generic HTTP 404 errors."
              value:
                error_code: 404
                message: "HTTP 404 Not Found"
            cluster_not_found:
              description: "Thrown when using a non-existing cluster ID."
              value:
                error_code: 404
                message: "Cluster my-cluster cannot be found."
            unknown_topic_or_partition:
              description: "Thrown when using a non-existing topic name or partition ID."
              value:
                error_code: 40403
                message: "This server does not host this topic-partition."

    TooManyRequestsErrorResponse:
      description: 'Indicates that a rate limit threshold has been reached, and the client should
        retry again later.'
      content:
        text/html:
          schema:
            type: string
          example:
            description: "A sample response from Jetty's DoSFilter."
            value: '<html>
                        <head>
                            <meta http-equiv="Content-Type" content="text/html;charset=utf-8"/>
                            <title>Error 429 Too Many Requests</title>
                        </head>
                        <body>
                            <h2>HTTP ERROR 429 Too Many Requests</h2>
                            <table>
                                <tr>
                                    <th>URI:</th>
                                    <td>/v3/clusters/my-cluster</td>
                                </tr>
                                <tr>
                                    <th>STATUS:</th>
                                    <td>429</td>
                                </tr>
                                <tr>
                                    <th>MESSAGE:</th>
                                    <td>Too Many Requests</td>
                                </tr>
                                <tr>
                                    <th>SERVLET:</th>
                                    <td>default</td>
                                </tr>
                            </table>
                        </body>
                    </html>'

    RequestEntityTooLargeErrorResponse:
      description: 'This implies the client is sending a request payload that is larger than the maximum message size the
        server can accept.'
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
          examples:
            produce_records_expects_json:
              description: "Thrown by /records API if payload size exceeds the message max size"
              value:
                error_code: 413
                message:  "The request included a message larger than the maximum message size the server can accept."

    UnsupportedMediaTypeErrorResponse:
      description: 'This implies the client is sending the request payload format in an unsupported format.'
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
          examples:
            produce_records_expects_json:
              description: "Thrown by /records API if payload format content-type doesn't match expected application/json"
              value:
                error_code: 415
                message:  "HTTP 415 Unsupported Media Type"

    ServerErrorResponse:
      description: 'A server-side problem that might not be addressable from the client side.
        Retriable Kafka errors will contain error code 50003 in the response body.'
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
          examples:
            generic_internal_server_error:
              description: "Thrown for generic HTTP 500 errors."
              value:
                error_code: 500
                message: "Internal Server Error"

tags:
  - name: Records (v3)
    description: |-
      [![Generally Available](https://img.shields.io/badge/Lifecycle%20Stage-Generally%20Available-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)
